{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, re, sys, csv, chardet\n",
    "sys.path.append(\"..\")\n",
    "from gutenberg_cleaner import super_cleaner\n",
    "from modules.gutenberg_text_utils import non_novels, remove_above_strings, remove_below_strings, publishers, short_scraps, long_scraps\n",
    "\n",
    "#Toggle between source_files and test_files (a test_files directory can be created manually and populated with a few files). This is useful for debugging problematic files, rather than doing a full processing run.\n",
    "directory = '../sources/gutenberg_source_files'\n",
    "\n",
    "#Only include novels. If turned on this will delete files that are included in non_novels.py.\n",
    "novels = 'on'\n",
    "\n",
    "def novels_only(directory: str):\n",
    "    if novels == 'on':\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                if file in non_novels:\n",
    "                    os.remove(os.path.join(root, file))\n",
    "\n",
    "def detect_file_encodings(directory, csv_file):\n",
    "    encodings = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            raw_data = f.read()\n",
    "            result = chardet.detect(raw_data)\n",
    "            encodings[filename] = result['encoding']\n",
    "\n",
    "    with open(csv_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['Filename', 'Encoding'])\n",
    "        for filename, encoding in encodings.items():\n",
    "            writer.writerow([filename, encoding])\n",
    "\n",
    "def convert_files_to_utf8(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, 'rb') as f:\n",
    "            result = chardet.detect(f.read())\n",
    "        if result['encoding'] == 'ascii' or result['encoding'] == 'utf-8':\n",
    "            with open(file_path, 'r', encoding=result['encoding']) as f:\n",
    "                content = f.read()\n",
    "            with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(content)\n",
    "\n",
    "def rename_files(directory):\n",
    "    for dirpath, dirnames, filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            old_path = os.path.join(dirpath, filename)\n",
    "            new_filename = filename.strip().replace(' ', '').replace('complete', '')\n",
    "            new_path = os.path.join(dirpath, new_filename)\n",
    "            os.rename(old_path, new_path)\n",
    "\n",
    "def additional_gutenberg_clean(text: str):\n",
    "    lines = text.splitlines()\n",
    "    new_text = ''\n",
    "    blank_lines = 0\n",
    "    skip = 0\n",
    "    for line in lines:\n",
    "        if '***END OF THE PROJECT GUTENBERG EBOOK' in line:\n",
    "            line = line.split('***END OF THE PROJECT GUTENBERG EBOOK')[0]\n",
    "            new_text += line + '\\n'\n",
    "            break\n",
    "        if '      *      *      *      *      *' in line:\n",
    "            line = line.split('      *      *      *      *      *')[0]\n",
    "            new_text += line + '\\n'\n",
    "            break\n",
    "        if skip > 0:\n",
    "            skip -= 1\n",
    "            continue\n",
    "        if 'Transcriber\\'s note:' in line:\n",
    "            skip = 8\n",
    "        if 'Transcriber\\'s note:' in line: \n",
    "            line = ''\n",
    "        if 'First published' in line:\n",
    "            skip = 2 # Skip the current and next lines\n",
    "            continue # Skip the current iteration and move to the next one\n",
    "        if 'Footnotes' in line:\n",
    "            line = line.split('Footnotes')[0]\n",
    "            new_text += line + '\\n'\n",
    "            break\n",
    "        if 'These Short Books' in line:\n",
    "            line = line.split('These Short Books')[0]\n",
    "            new_text += line + '\\n'\n",
    "            break\n",
    "        # Check if the current line is centered by checking if it starts and ends with a certain number of spaces.\n",
    "        # You can adjust the number of spaces to fit your needs.\n",
    "        if len(line) > 10 and (line.startswith(' '*15) or line.endswith(' '*15)):\n",
    "            continue # Skip this iteration and move to the next one\n",
    "        new_text += line + '\\n'\n",
    "    return new_text\n",
    "\n",
    "def remove_indented_text(text: str, num_spaces: int):\n",
    "    pattern = r'^\\s{{{}}}.+'.format(num_spaces)\n",
    "    new_text = re.sub(pattern, '', text, flags=re.MULTILINE)\n",
    "    return new_text\n",
    "\n",
    "def remove_above_blank_lines(text: str, num_blank_lines: int):\n",
    "    pattern = r'(\\n[ \\t]*\\n){{{}}}'.format(num_blank_lines)\n",
    "    sections = re.split(pattern, text, flags=re.DOTALL)\n",
    "    last_section = sections[-1]\n",
    "    if 'Editorial note:' in last_section:\n",
    "        last_section = last_section.split('Editorial note:')[1]\n",
    "    return last_section\n",
    "\n",
    "def remove_roman_numeral_lines(text: str):\n",
    "    pattern = r'^\\s*(?=[MDCLXVI])(M{0,3})(C[MD]|D?C{0,3})(X[CL]|L?X{0,3})(I[XV]|V?I{0,3})\\.'\n",
    "    lines = text.splitlines()\n",
    "    new_text = ''\n",
    "    for line in lines:\n",
    "        if not re.match(pattern, line):\n",
    "            new_text += line + '\\n'\n",
    "    return new_text\n",
    "\n",
    "def remove_bracketed_text(text: str):\n",
    "    pattern = r'\\[[^\\]]*?\\]'\n",
    "    new_text = re.sub(pattern, '', text, flags=re.DOTALL)\n",
    "    return new_text\n",
    "\n",
    "def remove_deleted_lines(text: str):\n",
    "    lines = text.splitlines()\n",
    "    new_text = ''\n",
    "    for line in lines:\n",
    "        if '[deleted]' not in line:\n",
    "            new_text += line + '\\n'\n",
    "    return new_text\n",
    "\n",
    "def remove_publishers(text: str, publishers: list) -> str:\n",
    "    new_text = text\n",
    "    for string in publishers:\n",
    "        new_text = new_text.replace(string, '')\n",
    "    return new_text\n",
    "\n",
    "def remove_short_scraps(text: str, short_scraps: list) -> str:\n",
    "    new_text = text\n",
    "    for string in short_scraps:\n",
    "        new_text = new_text.replace(string, '')\n",
    "    return new_text\n",
    "\n",
    "def remove_long_scraps(text: str, long_scraps: list) -> str:\n",
    "    new_text = text\n",
    "    for string in long_scraps:\n",
    "        new_text = new_text.replace(string, '')\n",
    "    return new_text\n",
    "\n",
    "def remove_above_strings_in_text(text: str):\n",
    "    for string in remove_above_strings:\n",
    "        if string in text:\n",
    "            sections = text.split(string)\n",
    "            last_section = sections[-1]\n",
    "            text = string + last_section\n",
    "    return text\n",
    "\n",
    "def remove_below_strings_in_text(text: str):\n",
    "    for string in remove_below_strings:\n",
    "        if string in text:\n",
    "            sections = text.split(string)\n",
    "            first_section = sections[0]\n",
    "            text = first_section + string\n",
    "    return text\n",
    "\n",
    "rename_files(directory)\n",
    "\n",
    "# Run the novels_only function\n",
    "novels_only(directory)\n",
    "\n",
    "# Run the detect file encodings function. This is only needs to be run to ascertain the encoding of files.\n",
    "# detect_file_encodings(directory, 'output/file_encodings.csv')\n",
    "\n",
    "# Convert from ascii to UTF-8 encoding\n",
    "convert_files_to_utf8(directory) \n",
    "\n",
    "# Run the functions (the order is important).\n",
    "for filename in os.listdir(directory):\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        text = f.read()\n",
    "    cleaned_text = super_cleaner(text, min_token=5, max_token=600)\n",
    "    cleaned_text = remove_indented_text(cleaned_text, 6)\n",
    "    cleaned_text = additional_gutenberg_clean(cleaned_text)\n",
    "    cleaned_text = remove_roman_numeral_lines(cleaned_text)\n",
    "    cleaned_text = remove_publishers(cleaned_text, publishers)\n",
    "    cleaned_text = remove_short_scraps(cleaned_text, short_scraps)\n",
    "    cleaned_text = remove_long_scraps(cleaned_text, long_scraps)\n",
    "    cleaned_text = remove_above_blank_lines(cleaned_text, 15)\n",
    "    cleaned_text = remove_bracketed_text(cleaned_text)\n",
    "    cleaned_text = remove_deleted_lines(cleaned_text)\n",
    "    cleaned_text = remove_above_strings_in_text(cleaned_text)\n",
    "    cleaned_text = remove_below_strings_in_text(cleaned_text)\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        f.write(cleaned_text)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
